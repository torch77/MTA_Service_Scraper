# Notes for Creation of MTA Scraper

Python Scraper 
	- Scraper reads XML file in as beautiful soup object
	- Then we parse accoring to following logic
		- if response code is good, continue
			- for each service (subway, bus, etc)
				- store pertinent information in variables for each line
				- append varibles into dicitionary for each serice
				
		- pass dictionaries to function to update sqlite database
			- open/connect to db
			- for each service	
				- for each line
					- extract and store dictionary values
					- date hour needs some parsing b/c MTA pads hours with a space and not zero
					- get primary keys for line and service based on hard coded functions
					- Insert values into db
			- commit each service
			
AWS

- Set up Ubuntu Micro 14.04 LTS instance using standard settings
- get pem, save into xshell
- install conda
	- wget http://repo.continuum.io/archive/Anaconda3-4.1.1-Linux-x86_64.sh
	- bash Anaconda3-4.1.1-Linux-x86_64.sh
- install sqlite3 package from apt
- move sqlite db and python file to /usr/local/bin
	- need to hard code db path into python script as /usr/local/bin/....sqlite
- set up cron job using crontab
	- run every hour 10 minutes into the hour
	- hardcode anaconda python path into job to avoid package issues

	
#### TO DO#### 
# need to implement error catching 
# more error/anamolous case catching, don't just crash
# new class to write to database
# automatic download of db as a backup?